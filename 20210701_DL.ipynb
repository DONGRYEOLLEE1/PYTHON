{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757765fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7642f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea06d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe586b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "np_data = np.array(data)\n",
    "np_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d202d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65016071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680d751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a8b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a121aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbdc986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da5c2096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f = torch.FloatTensor(data)\n",
    "x_data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b926dbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method dim of Tensor object at 0x000001E4CDFAF340>\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x_data_f.dim)\n",
    "print(x_data_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92babdda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fce1481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 7.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.FloatTensor([[1,3]])\n",
    "t2 = torch.FloatTensor([[2,4]])\n",
    "print(t1 + t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58ff9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 5.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.FloatTensor([[1,3]])\n",
    "t2 = torch.FloatTensor([[2]])\n",
    "print(t1+t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "badb4800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f.mean() # 1,2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cef2eeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f.mean(dim=0)\n",
    "# 1 2\n",
    "# 3 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33df2a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 3.5000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_f.mean(dim=1)\n",
    "# 1 2\n",
    "# 3 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67667f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.FloatTensor([[1,3]])\n",
    "t2 = torch.FloatTensor([[2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fff480c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([t1, t2], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25d12b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3., 2., 4.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([t1, t2], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47118a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 3.]],\n",
       "\n",
       "        [[2., 4.]],\n",
       "\n",
       "        [[5., 6.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.FloatTensor([[5,6]])\n",
    "t4 = torch.stack([t1, t2, t3])\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9433248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.]],\n",
       "\n",
       "        [[1., 1.]],\n",
       "\n",
       "        [[1., 1.]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(t4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5a3e59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.]],\n",
       "\n",
       "        [[0., 0.]],\n",
       "\n",
       "        [[0., 0.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(t4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bea63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "\n",
    "# y = 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea3dc738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설 설정\n",
    "# y = W * x + b\n",
    "# 기존 사이킷런 머신 러닝: MSE 평균 제곱 오차\n",
    "\n",
    "# cost funtion(비용함수) = loss function(손실함수) = error function(오차함수) = objective function(목적함수)\n",
    "# 옵티마이져 (기울기가 제일 낮은 곳 , 경사 하강법(gradient descent) 사용) (Ex. 머신러닝에서 fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fd82f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ad644bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros(1, requires_grad = True) # 바꿔가면서 쓸 변수다 .\n",
    "# 기울기를 0으로 세팅\n",
    "b = torch.zeros(1, requires_grad = True) # 바꿔가면서 쓸 변수다 .\n",
    "# 바이어스 0으로 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7348cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8f0c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 세팅 값 y = 0*x + 0\n",
    "\n",
    "# 가설\n",
    "hypothesis = X_train*W+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95784d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15cb1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis - y_train)**2) # 원본값과 비교 / 평균ik 제곱 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aac51046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fc81eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD 경사 하강법 적용 / lr 러닝 레이트가 너무 크면 빨리 찾아갈 수는 있지만 어디에 수렴하질 못함(발산한다) / 작게 잡으면 늦어질순 있지만 발산 정도는 낮아진다.\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD([W, b], lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c381885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0으로 시작하겠다\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# 추적\n",
    "cost.backward()\n",
    "\n",
    "# 추적값 업데이트\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d523ca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0/20000 W: 0.019, b:0.008 , cost18.66667\n",
      "Epoch 200/20000 W: 1.513, b:0.624 , cost0.28531\n",
      "Epoch 400/20000 W: 1.686, b:0.661 , cost0.06679\n",
      "Epoch 600/20000 W: 1.717, b:0.637 , cost0.05845\n",
      "Epoch 800/20000 W: 1.732, b:0.608 , cost0.05306\n",
      "Epoch1000/20000 W: 1.745, b:0.579 , cost0.04820\n",
      "Epoch1200/20000 W: 1.757, b:0.552 , cost0.04378\n",
      "Epoch1400/20000 W: 1.768, b:0.526 , cost0.03976\n",
      "Epoch1600/20000 W: 1.779, b:0.502 , cost0.03612\n",
      "Epoch1800/20000 W: 1.790, b:0.478 , cost0.03281\n",
      "Epoch2000/20000 W: 1.800, b:0.456 , cost0.02980\n",
      "Epoch2200/20000 W: 1.809, b:0.434 , cost0.02707\n",
      "Epoch2400/20000 W: 1.818, b:0.414 , cost0.02458\n",
      "Epoch2600/20000 W: 1.826, b:0.394 , cost0.02233\n",
      "Epoch2800/20000 W: 1.835, b:0.376 , cost0.02028\n",
      "Epoch3000/20000 W: 1.842, b:0.358 , cost0.01842\n",
      "Epoch3200/20000 W: 1.850, b:0.341 , cost0.01673\n",
      "Epoch3400/20000 W: 1.857, b:0.325 , cost0.01520\n",
      "Epoch3600/20000 W: 1.864, b:0.310 , cost0.01381\n",
      "Epoch3800/20000 W: 1.870, b:0.296 , cost0.01254\n",
      "Epoch4000/20000 W: 1.876, b:0.282 , cost0.01139\n",
      "Epoch4200/20000 W: 1.882, b:0.268 , cost0.01035\n",
      "Epoch4400/20000 W: 1.887, b:0.256 , cost0.00940\n",
      "Epoch4600/20000 W: 1.893, b:0.244 , cost0.00854\n",
      "Epoch4800/20000 W: 1.898, b:0.232 , cost0.00775\n",
      "Epoch5000/20000 W: 1.903, b:0.222 , cost0.00704\n",
      "Epoch5200/20000 W: 1.907, b:0.211 , cost0.00640\n",
      "Epoch5400/20000 W: 1.911, b:0.201 , cost0.00581\n",
      "Epoch5600/20000 W: 1.916, b:0.192 , cost0.00528\n",
      "Epoch5800/20000 W: 1.920, b:0.183 , cost0.00479\n",
      "Epoch6000/20000 W: 1.923, b:0.174 , cost0.00435\n",
      "Epoch6200/20000 W: 1.927, b:0.166 , cost0.00395\n",
      "Epoch6400/20000 W: 1.930, b:0.158 , cost0.00359\n",
      "Epoch6600/20000 W: 1.934, b:0.151 , cost0.00326\n",
      "Epoch6800/20000 W: 1.937, b:0.144 , cost0.00296\n",
      "Epoch7000/20000 W: 1.940, b:0.137 , cost0.00269\n",
      "Epoch7200/20000 W: 1.943, b:0.131 , cost0.00245\n",
      "Epoch7400/20000 W: 1.945, b:0.124 , cost0.00222\n",
      "Epoch7600/20000 W: 1.948, b:0.119 , cost0.00202\n",
      "Epoch7800/20000 W: 1.950, b:0.113 , cost0.00183\n",
      "Epoch8000/20000 W: 1.953, b:0.108 , cost0.00166\n",
      "Epoch8200/20000 W: 1.955, b:0.103 , cost0.00151\n",
      "Epoch8400/20000 W: 1.957, b:0.098 , cost0.00137\n",
      "Epoch8600/20000 W: 1.959, b:0.093 , cost0.00125\n",
      "Epoch8800/20000 W: 1.961, b:0.089 , cost0.00113\n",
      "Epoch9000/20000 W: 1.963, b:0.085 , cost0.00103\n",
      "Epoch9200/20000 W: 1.965, b:0.081 , cost0.00093\n",
      "Epoch9400/20000 W: 1.966, b:0.077 , cost0.00085\n",
      "Epoch9600/20000 W: 1.968, b:0.073 , cost0.00077\n",
      "Epoch9800/20000 W: 1.969, b:0.070 , cost0.00070\n",
      "Epoch10000/20000 W: 1.971, b:0.067 , cost0.00064\n",
      "Epoch10200/20000 W: 1.972, b:0.063 , cost0.00058\n",
      "Epoch10400/20000 W: 1.973, b:0.060 , cost0.00052\n",
      "Epoch10600/20000 W: 1.975, b:0.058 , cost0.00048\n",
      "Epoch10800/20000 W: 1.976, b:0.055 , cost0.00043\n",
      "Epoch11000/20000 W: 1.977, b:0.052 , cost0.00039\n",
      "Epoch11200/20000 W: 1.978, b:0.050 , cost0.00036\n",
      "Epoch11400/20000 W: 1.979, b:0.048 , cost0.00032\n",
      "Epoch11600/20000 W: 1.980, b:0.045 , cost0.00029\n",
      "Epoch11800/20000 W: 1.981, b:0.043 , cost0.00027\n",
      "Epoch12000/20000 W: 1.982, b:0.041 , cost0.00024\n",
      "Epoch12200/20000 W: 1.983, b:0.039 , cost0.00022\n",
      "Epoch12400/20000 W: 1.984, b:0.037 , cost0.00020\n",
      "Epoch12600/20000 W: 1.984, b:0.036 , cost0.00018\n",
      "Epoch12800/20000 W: 1.985, b:0.034 , cost0.00017\n",
      "Epoch13000/20000 W: 1.986, b:0.032 , cost0.00015\n",
      "Epoch13200/20000 W: 1.986, b:0.031 , cost0.00014\n",
      "Epoch13400/20000 W: 1.987, b:0.029 , cost0.00012\n",
      "Epoch13600/20000 W: 1.988, b:0.028 , cost0.00011\n",
      "Epoch13800/20000 W: 1.988, b:0.027 , cost0.00010\n",
      "Epoch14000/20000 W: 1.989, b:0.025 , cost0.00009\n",
      "Epoch14200/20000 W: 1.989, b:0.024 , cost0.00008\n",
      "Epoch14400/20000 W: 1.990, b:0.023 , cost0.00008\n",
      "Epoch14600/20000 W: 1.990, b:0.022 , cost0.00007\n",
      "Epoch14800/20000 W: 1.991, b:0.021 , cost0.00006\n",
      "Epoch15000/20000 W: 1.991, b:0.020 , cost0.00006\n",
      "Epoch15200/20000 W: 1.992, b:0.019 , cost0.00005\n",
      "Epoch15400/20000 W: 1.992, b:0.018 , cost0.00005\n",
      "Epoch15600/20000 W: 1.992, b:0.017 , cost0.00004\n",
      "Epoch15800/20000 W: 1.993, b:0.017 , cost0.00004\n",
      "Epoch16000/20000 W: 1.993, b:0.016 , cost0.00004\n",
      "Epoch16200/20000 W: 1.993, b:0.015 , cost0.00003\n",
      "Epoch16400/20000 W: 1.994, b:0.014 , cost0.00003\n",
      "Epoch16600/20000 W: 1.994, b:0.014 , cost0.00003\n",
      "Epoch16800/20000 W: 1.994, b:0.013 , cost0.00002\n",
      "Epoch17000/20000 W: 1.995, b:0.012 , cost0.00002\n",
      "Epoch17200/20000 W: 1.995, b:0.012 , cost0.00002\n",
      "Epoch17400/20000 W: 1.995, b:0.011 , cost0.00002\n",
      "Epoch17600/20000 W: 1.995, b:0.011 , cost0.00002\n",
      "Epoch17800/20000 W: 1.995, b:0.010 , cost0.00002\n",
      "Epoch18000/20000 W: 1.996, b:0.010 , cost0.00001\n",
      "Epoch18200/20000 W: 1.996, b:0.009 , cost0.00001\n",
      "Epoch18400/20000 W: 1.996, b:0.009 , cost0.00001\n",
      "Epoch18600/20000 W: 1.996, b:0.008 , cost0.00001\n",
      "Epoch18800/20000 W: 1.996, b:0.008 , cost0.00001\n",
      "Epoch19000/20000 W: 1.997, b:0.008 , cost0.00001\n",
      "Epoch19200/20000 W: 1.997, b:0.007 , cost0.00001\n",
      "Epoch19400/20000 W: 1.997, b:0.007 , cost0.00001\n",
      "Epoch19600/20000 W: 1.997, b:0.007 , cost0.00001\n",
      "Epoch19800/20000 W: 1.997, b:0.006 , cost0.00001\n"
     ]
    }
   ],
   "source": [
    "# 종합\n",
    "\n",
    "X_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "\n",
    "W = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr = 0.001)\n",
    "\n",
    "# iter_ 값과 같은 반복요구값\n",
    "nb_epochs = 20000\n",
    "list_cost = []\n",
    "for epoch in range(nb_epochs):\n",
    "    hypothesis = X_train*W+b\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 중간마다 확인하고 싶다\n",
    "    if epoch % 200 == 0:\n",
    "        # list_cost.append(float(cost.item()))\n",
    "        print('Epoch{:4d}/{} W: {:.3f}, b:{:.3f} , cost{:.5f}'.\n",
    "             format( epoch, nb_epochs, W.item(), b.item(), cost.item()))\n",
    "        \n",
    "# import matplotlib.pyplot as plt\n",
    "# print()\n",
    "# plt.plot(range(100), list_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1346325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    0/200000 W1 : 0.235, W2 : 0.235, W3 : 0.239, b : 0.003 , cost : 29661.80078\n",
      "Epoch : 5000/200000 W1 : 0.733, W2 : 0.582, W3 : 0.691, b : 0.007 , cost : 0.47267\n",
      "Epoch : 10000/200000 W1 : 0.762, W2 : 0.558, W3 : 0.686, b : 0.006 , cost : 0.43392\n",
      "Epoch : 15000/200000 W1 : 0.779, W2 : 0.553, W3 : 0.674, b : 0.005 , cost : 0.42241\n",
      "Epoch : 20000/200000 W1 : 0.792, W2 : 0.553, W3 : 0.662, b : 0.004 , cost : 0.41417\n",
      "Epoch : 25000/200000 W1 : 0.804, W2 : 0.555, W3 : 0.649, b : 0.003 , cost : 0.40692\n",
      "Epoch : 30000/200000 W1 : 0.814, W2 : 0.557, W3 : 0.637, b : 0.002 , cost : 0.40039\n",
      "Epoch : 35000/200000 W1 : 0.824, W2 : 0.559, W3 : 0.625, b : 0.001 , cost : 0.39449\n",
      "Epoch : 40000/200000 W1 : 0.833, W2 : 0.561, W3 : 0.614, b : -0.001 , cost : 0.38914\n",
      "Epoch : 45000/200000 W1 : 0.842, W2 : 0.563, W3 : 0.604, b : -0.002 , cost : 0.38429\n",
      "Epoch : 50000/200000 W1 : 0.850, W2 : 0.564, W3 : 0.594, b : -0.004 , cost : 0.37991\n",
      "Epoch : 55000/200000 W1 : 0.858, W2 : 0.566, W3 : 0.584, b : -0.005 , cost : 0.37594\n",
      "Epoch : 60000/200000 W1 : 0.866, W2 : 0.568, W3 : 0.575, b : -0.006 , cost : 0.37235\n",
      "Epoch : 65000/200000 W1 : 0.873, W2 : 0.569, W3 : 0.567, b : -0.008 , cost : 0.36909\n",
      "Epoch : 70000/200000 W1 : 0.880, W2 : 0.571, W3 : 0.558, b : -0.010 , cost : 0.36614\n",
      "Epoch : 75000/200000 W1 : 0.886, W2 : 0.572, W3 : 0.551, b : -0.011 , cost : 0.36345\n",
      "Epoch : 80000/200000 W1 : 0.893, W2 : 0.573, W3 : 0.543, b : -0.013 , cost : 0.36102\n",
      "Epoch : 85000/200000 W1 : 0.898, W2 : 0.575, W3 : 0.536, b : -0.014 , cost : 0.35882\n",
      "Epoch : 90000/200000 W1 : 0.904, W2 : 0.576, W3 : 0.530, b : -0.016 , cost : 0.35681\n",
      "Epoch : 95000/200000 W1 : 0.909, W2 : 0.577, W3 : 0.523, b : -0.018 , cost : 0.35498\n",
      "Epoch : 100000/200000 W1 : 0.914, W2 : 0.578, W3 : 0.517, b : -0.019 , cost : 0.35333\n",
      "Epoch : 105000/200000 W1 : 0.919, W2 : 0.579, W3 : 0.511, b : -0.021 , cost : 0.35183\n",
      "Epoch : 110000/200000 W1 : 0.924, W2 : 0.580, W3 : 0.506, b : -0.023 , cost : 0.35045\n",
      "Epoch : 115000/200000 W1 : 0.928, W2 : 0.581, W3 : 0.501, b : -0.025 , cost : 0.34919\n",
      "Epoch : 120000/200000 W1 : 0.932, W2 : 0.582, W3 : 0.496, b : -0.026 , cost : 0.34806\n",
      "Epoch : 125000/200000 W1 : 0.936, W2 : 0.583, W3 : 0.491, b : -0.028 , cost : 0.34702\n",
      "Epoch : 130000/200000 W1 : 0.940, W2 : 0.584, W3 : 0.487, b : -0.030 , cost : 0.34606\n",
      "Epoch : 135000/200000 W1 : 0.944, W2 : 0.584, W3 : 0.482, b : -0.032 , cost : 0.34519\n",
      "Epoch : 140000/200000 W1 : 0.947, W2 : 0.585, W3 : 0.478, b : -0.034 , cost : 0.34439\n",
      "Epoch : 145000/200000 W1 : 0.950, W2 : 0.586, W3 : 0.475, b : -0.035 , cost : 0.34366\n",
      "Epoch : 150000/200000 W1 : 0.953, W2 : 0.587, W3 : 0.471, b : -0.037 , cost : 0.34300\n",
      "Epoch : 155000/200000 W1 : 0.956, W2 : 0.587, W3 : 0.467, b : -0.039 , cost : 0.34237\n",
      "Epoch : 160000/200000 W1 : 0.959, W2 : 0.588, W3 : 0.464, b : -0.041 , cost : 0.34180\n",
      "Epoch : 165000/200000 W1 : 0.962, W2 : 0.588, W3 : 0.461, b : -0.043 , cost : 0.34127\n",
      "Epoch : 170000/200000 W1 : 0.964, W2 : 0.589, W3 : 0.458, b : -0.045 , cost : 0.34079\n",
      "Epoch : 175000/200000 W1 : 0.967, W2 : 0.589, W3 : 0.455, b : -0.047 , cost : 0.34034\n",
      "Epoch : 180000/200000 W1 : 0.969, W2 : 0.590, W3 : 0.452, b : -0.049 , cost : 0.33992\n",
      "Epoch : 185000/200000 W1 : 0.971, W2 : 0.590, W3 : 0.450, b : -0.051 , cost : 0.33954\n",
      "Epoch : 190000/200000 W1 : 0.973, W2 : 0.591, W3 : 0.447, b : -0.053 , cost : 0.33917\n",
      "Epoch : 195000/200000 W1 : 0.975, W2 : 0.591, W3 : 0.445, b : -0.055 , cost : 0.33884\n"
     ]
    }
   ],
   "source": [
    "# 가설 설정\n",
    "# y = W1 * x1 + W2 * x2 + W3 * x3 + b\n",
    "\n",
    "# feature 가 3 개 , 포인트가 5개 / 결과값이 1개\n",
    "X1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "X2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "X3_train = torch.FloatTensor([[75], [93], [90], [100], [73]])\n",
    "\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "W1 = torch.zeros(1, requires_grad = True)\n",
    "W2 = torch.zeros(1, requires_grad = True)\n",
    "W3 = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([W1,W2,W3, b], lr = 0.000008)\n",
    "nb_epochs = 200000\n",
    "list_cost = []\n",
    "for epoch in range(nb_epochs):\n",
    "    hypothesis = X1_train*W1+X2_train*W2+X3_train*W3+b\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 중간마다 확인하고 싶다\n",
    "    if epoch % 5000 == 0:\n",
    "        # list_cost.append(float(cost.item()))\n",
    "        print('Epoch : {:4d}/{} W1 : {:.3f}, W2 : {:.3f}, W3 : {:.3f}, b : {:.3f} , cost : {:.5f}'.\n",
    "             format( epoch, nb_epochs, W1.item(),W2.item(),W3.item(), b.item(), cost.item()))\n",
    "\n",
    "# 다변량에 있어서 0으로 수렴하기는 어렵다\n",
    "# W1, W2, W3, b 값이 바뀌지 않고 일정할 때 만족하는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c862145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간소화\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bb2d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1) # (input_dim=1, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31fd0ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.4195]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0167], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())) # 첫번째 텐서 = W , 두번째 텐서 = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4e360fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf92ab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.9479]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3944], requires_grad=True)]\n",
      "Epoch :    0/2000 loss : 36.05731\n",
      "Epoch :  100/2000 loss : 0.17800\n",
      "Epoch :  200/2000 loss : 0.10999\n",
      "Epoch :  300/2000 loss : 0.06797\n",
      "Epoch :  400/2000 loss : 0.04200\n",
      "Epoch :  500/2000 loss : 0.02595\n",
      "Epoch :  600/2000 loss : 0.01604\n",
      "Epoch :  700/2000 loss : 0.00991\n",
      "Epoch :  800/2000 loss : 0.00612\n",
      "Epoch :  900/2000 loss : 0.00378\n",
      "Epoch : 1000/2000 loss : 0.00234\n",
      "Epoch : 1100/2000 loss : 0.00144\n",
      "Epoch : 1200/2000 loss : 0.00089\n",
      "Epoch : 1300/2000 loss : 0.00055\n",
      "Epoch : 1400/2000 loss : 0.00034\n",
      "Epoch : 1500/2000 loss : 0.00021\n",
      "Epoch : 1600/2000 loss : 0.00013\n",
      "Epoch : 1700/2000 loss : 0.00008\n",
      "Epoch : 1800/2000 loss : 0.00005\n",
      "Epoch : 1900/2000 loss : 0.00003\n",
      "Epoch : 2000/2000 loss : 0.00002\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "X_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "model = nn.Linear(1,1) # (input_dim=1, output_dim=1)\n",
    "\n",
    "print(list(model.parameters())) # 첫번째 텐서 = W , 두번째 텐서 = b\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    prediction = model(X_train)\n",
    "    cost = F.mse_loss(prediction, y_train)   \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch : {:4d}/{} loss : {:.5f}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e92653ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0039]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input = torch.FloatTensor([[1.5]])\n",
    "pred_y =model(new_input)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb1d3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a094324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2869ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.FloatTensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831c8579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Function Softmax\n",
    "# K개의 값이 존재할 때 각각의 값의 편차를 확대시켜 \n",
    "# 큰 값은 상대적으로 더 크게, 작은 값은 상대적으로 더 작게 만든 다음에 normalization 시키는 함수다\n",
    "\n",
    "hypothesis = F.softmax(z, dim = 0)\n",
    "hypothesis\n",
    "\n",
    "# *** 지수 처리는 필수다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771d0135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09003057317038046"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(1.0)/(np.exp(1.0) + np.exp(2.0) + np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a8ff0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24472847105479767"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.0)/(np.exp(1.0) + np.exp(2.0) + np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d19b5ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6652409557748219"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.0)/(np.exp(1.0) + np.exp(2.0) + np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a70c4023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e159de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb55cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0915992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539421b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51aa89d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = dsets.MNIST(root = 'MNIST_data/', train = True, transform = transforms.ToTensor(), \n",
    "                         download = True)\n",
    "mnist_test = dsets.MNIST(root = 'MNIST_data/', train = False, transform = transforms.ToTensor(), \n",
    "                         download = True)\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf1345a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c367b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "image, label = mnist_train[0]\n",
    "print(image.shape, label)\n",
    "\n",
    "#### [흑백, 가로, 세로] 숫자 '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40430d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# plt.imshow(image.reshape(28, 28), cap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8387a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear( 28*28, 10, bias = True) # input_dim = 28*28, output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb69028",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddf7afc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.534558892\n",
      "Epoch: 0002 cost= 0.359259784\n",
      "Epoch: 0003 cost= 0.331140339\n",
      "Epoch: 0004 cost= 0.316343844\n",
      "Epoch: 0005 cost= 0.307305545\n",
      "Epoch: 0006 cost= 0.300468057\n",
      "Epoch: 0007 cost= 0.294988215\n",
      "Epoch: 0008 cost= 0.290935904\n",
      "Epoch: 0009 cost= 0.287606329\n",
      "Epoch: 0010 cost= 0.284453034\n",
      "Epoch: 0011 cost= 0.281795233\n",
      "Epoch: 0012 cost= 0.279786289\n",
      "Epoch: 0013 cost= 0.277701825\n",
      "Epoch: 0014 cost= 0.275894791\n",
      "Epoch: 0015 cost= 0.274536222\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        y = y\n",
    "        \n",
    "        hyphthesis = linear(X)\n",
    "        cost = criterion(hyphthesis, y)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += cost/total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' %(epoch+1), 'cost=', \"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "047442a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8835999965667725\n",
      "label: 6\n",
      "Prediction: 6\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28*28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    \n",
    "    correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('acc:', accuracy.item())\n",
    "    \n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    X_single_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float()\n",
    "    y_single_data = mnist_test.test_labels[r:r+1]\n",
    "    print('label:', y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction:', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    #plt.imshow(mnist_test.test_data[r:r+1].view(28, 28), cmap = 'Greys', interpolation = 'nearest')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f86f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cf16645",
   "metadata": {},
   "source": [
    "# Neural Network - DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddafb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layering\n",
    "\n",
    "# nn.Linear(784, 10)  784 -> 10\n",
    "# 784 -> 256 -> 256 -> 10\n",
    "linear1 = nn.Linear(784, 256)\n",
    "linear2 = nn.Linear(256, 256)\n",
    "linear3 = nn.Linear(256, 10)\n",
    "relu = torch.nn.ReLU()    \n",
    "\n",
    "## 미분에서 문제가 생길경우, relu 사용해보자 (이미지 작업)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dee06d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.7677e-01,  3.2348e-01,  2.6216e-01,  ...,  4.9912e-01,\n",
       "         -5.6376e-01, -3.8905e-03],\n",
       "        [ 2.8482e-01, -4.0620e-02, -1.2190e-01,  ...,  1.6252e+00,\n",
       "          1.9711e-01, -7.0714e-01],\n",
       "        [ 1.2289e-01,  3.9199e-01,  1.3049e-01,  ..., -3.2131e-01,\n",
       "         -8.2046e-01,  5.0537e-01],\n",
       "        ...,\n",
       "        [ 7.8815e-01, -3.0617e+00,  1.6741e+00,  ...,  5.0366e-01,\n",
       "          5.5795e-01,  1.8928e+00],\n",
       "        [-6.2720e-01,  6.2964e-01, -1.3201e+00,  ...,  8.5647e-01,\n",
       "         -4.1795e-01, -2.7260e+00],\n",
       "        [-6.8437e-01, -1.0720e-01,  8.0460e-01,  ..., -3.2090e-01,\n",
       "          2.3372e+00, -1.7617e-03]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기화 작업\n",
    "nn.init.normal_(linear1.weight)\n",
    "nn.init.normal_(linear2.weight)\n",
    "nn.init.normal_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fde97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(linear1, relu, linear2, relu, linear3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be6f48e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 175.037689209\n",
      "Epoch: 0002 cost= 39.172035217\n",
      "Epoch: 0003 cost= 24.402217865\n",
      "Epoch: 0004 cost= 16.808706284\n",
      "Epoch: 0005 cost= 12.226678848\n",
      "Epoch: 0006 cost= 8.898686409\n",
      "Epoch: 0007 cost= 6.709106922\n",
      "Epoch: 0008 cost= 5.174489498\n",
      "Epoch: 0009 cost= 3.785637140\n",
      "Epoch: 0010 cost= 2.964432001\n",
      "Epoch: 0011 cost= 2.214947701\n",
      "Epoch: 0012 cost= 1.787160397\n",
      "Epoch: 0013 cost= 1.454652429\n",
      "Epoch: 0014 cost= 1.042757034\n",
      "Epoch: 0015 cost= 0.831265807\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "total_batch = len(data_loader)\n",
    "train_epochs = 15\n",
    "batch_size = 100\n",
    "for epoch in range(train_epochs):\n",
    "    avg_cost = 0\n",
    "    for X, y in data_loader:\n",
    "        X = X.view(-1, 28 * 28)\n",
    "        y = y\n",
    "        optimizer.zero_grad()\n",
    "        hyp = model(X)\n",
    "        cost = criterion(hyp, y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += cost/total_batch\n",
    "    print('Epoch:', '%04d' %(epoch+1), 'cost=', \"{:.9f}\".format(avg_cost))\n",
    "    \n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e3be2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9467999935150146\n",
      "label: 1\n",
      "Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28*28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    \n",
    "    correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('acc:', accuracy.item())\n",
    "    \n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    X_single_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float()\n",
    "    y_single_data = mnist_test.test_labels[r:r+1]\n",
    "    print('label:', y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction:', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    #plt.imshow(mnist_test.test_data[r:r+1].view(28, 28), cmap = 'Greys', interpolation = 'nearest')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294bb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bda7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
