{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e91bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import struct, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03bc534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind = 'train'):\n",
    "    labels_path = os.path.join(path, \"%s-labels-idx1-ubyte\"%kind)\n",
    "    images_path = os.path.join(path, \"%s-images-idx3-ubyte\"%kind)\n",
    "    # label\n",
    "    with open(labels_path, 'rb') as la_path:\n",
    "        magic, n = struct.unpack(\">II\", la_path.read(8))\n",
    "        labels = np.fromfile(la_path, dtype = np.uint8)\n",
    "    # image\n",
    "    with open(images_path, 'rb') as img_path:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", img_path.read(16))\n",
    "        images = np.fromfile(img_path, dtype = np.uint8).reshape(len(labels), 28**2)\n",
    "        images = ((images / 255) - 0.5) * 2\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5360cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 784\n",
      "50000 784\n",
      "10000 784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = load_mnist(\"./\", kind = 'train')\n",
    "X_test, y_test = load_mnist(\"./\", kind = 't10k')\n",
    "X_valid, y_valid = X_train[50000:, :], y_train[50000:]\n",
    "X_train, y_train = X_train[:50000, :], y_train[:50000]\n",
    "\n",
    "print(X_valid.shape[0], X_valid.shape[1])\n",
    "print(X_train.shape[0], X_train.shape[1])\n",
    "print(X_test.shape[0], X_test.shape[1])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0960b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals = np.mean(X_train, axis = 0)\n",
    "std_val = np.std(X_train)\n",
    "X_train_centered = (X_train - mean_vals) / std_val\n",
    "X_valid_centered = (X_valid - mean_vals) / std_val\n",
    "X_test_centered = (X_test - mean_vals) / std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02f7f074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_onehot = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "y_valid_onehot = tf.keras.utils.to_categorical(y_valid)\n",
    "\n",
    "y_train_onehot[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23639e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units = 50, \n",
    "    input_dim = X_train_centered.shape[1], \n",
    "    kernel_initializer = 'glorot_uniform', \n",
    "    bias_initializer = 'zeros', \n",
    "    activation = 'tanh'\n",
    "))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units = 50, \n",
    "    input_dim = 50, \n",
    "    kernel_initializer = 'glorot_uniform', \n",
    "    bias_initializer = 'zeros', \n",
    "    activation = 'tanh'\n",
    "))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units = 10, \n",
    "    input_dim = 50, \n",
    "    kernel_initializer = 'glorot_uniform', \n",
    "    bias_initializer = 'zeros', \n",
    "    activation = 'softmax'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6375ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 42,310\n",
      "Trainable params: 42,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e548439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(lr = 0.0001, decay = 1e-7, momentum = 0.9)\n",
    "model.compile(optimizer = sgd_optimizer, loss = \"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d64c8806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 1.5945 - val_loss: 1.1125\n",
      "Epoch 2/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 1.0029 - val_loss: 0.8110\n",
      "Epoch 3/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.7962 - val_loss: 0.6611\n",
      "Epoch 4/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.6788 - val_loss: 0.5696\n",
      "Epoch 5/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.6019 - val_loss: 0.5075\n",
      "Epoch 6/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.5472 - val_loss: 0.4626\n",
      "Epoch 7/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.5063 - val_loss: 0.4284\n",
      "Epoch 8/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.4744 - val_loss: 0.4017\n",
      "Epoch 9/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.4487 - val_loss: 0.3800\n",
      "Epoch 10/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.4276 - val_loss: 0.3620\n",
      "Epoch 11/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.4099 - val_loss: 0.3468\n",
      "Epoch 12/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3947 - val_loss: 0.3338\n",
      "Epoch 13/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3816 - val_loss: 0.3226\n",
      "Epoch 14/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3701 - val_loss: 0.3127\n",
      "Epoch 15/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3598 - val_loss: 0.3039\n",
      "Epoch 16/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3507 - val_loss: 0.2961\n",
      "Epoch 17/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3424 - val_loss: 0.2891\n",
      "Epoch 18/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3349 - val_loss: 0.2826\n",
      "Epoch 19/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3280 - val_loss: 0.2768\n",
      "Epoch 20/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3216 - val_loss: 0.2715\n",
      "Epoch 21/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3157 - val_loss: 0.2666\n",
      "Epoch 22/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3102 - val_loss: 0.2620\n",
      "Epoch 23/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3051 - val_loss: 0.2577\n",
      "Epoch 24/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.3003 - val_loss: 0.2537\n",
      "Epoch 25/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2957 - val_loss: 0.2500\n",
      "Epoch 26/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2914 - val_loss: 0.2465\n",
      "Epoch 27/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2873 - val_loss: 0.2431\n",
      "Epoch 28/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2834 - val_loss: 0.2400\n",
      "Epoch 29/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2797 - val_loss: 0.2370\n",
      "Epoch 30/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2762 - val_loss: 0.2342\n",
      "Epoch 31/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2728 - val_loss: 0.2315\n",
      "Epoch 32/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2695 - val_loss: 0.2290\n",
      "Epoch 33/50\n",
      "844/844 [==============================] - 1s 2ms/step - loss: 0.2664 - val_loss: 0.2265\n",
      "Epoch 34/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2634 - val_loss: 0.2241\n",
      "Epoch 35/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2605 - val_loss: 0.2219\n",
      "Epoch 36/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2577 - val_loss: 0.2197\n",
      "Epoch 37/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2550 - val_loss: 0.2176\n",
      "Epoch 38/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2524 - val_loss: 0.2156\n",
      "Epoch 39/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2499 - val_loss: 0.2135TA: 0s - loss: 0. - ETA: 0s - los\n",
      "Epoch 40/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2474 - val_loss: 0.2117\n",
      "Epoch 41/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2450 - val_loss: 0.2099\n",
      "Epoch 42/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2427 - val_loss: 0.2082\n",
      "Epoch 43/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2405 - val_loss: 0.2064\n",
      "Epoch 44/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2383 - val_loss: 0.2048\n",
      "Epoch 45/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2361 - val_loss: 0.2032\n",
      "Epoch 46/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2341 - val_loss: 0.2016\n",
      "Epoch 47/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2320 - val_loss: 0.2001\n",
      "Epoch 48/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2301 - val_loss: 0.1986\n",
      "Epoch 49/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2281 - val_loss: 0.1972\n",
      "Epoch 50/50\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.2262 - val_loss: 0.1958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ba8607f340>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_centered, y_train_onehot, batch_size = 64, epochs = 50, verbose = 1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cd9ce51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose = 0)\n",
    "y_train_pred[:3]\n",
    "y_test_pred = model.predict_classes(X_test_centered, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "478b9769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d2d80c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9354\n",
      "0.9354\n"
     ]
    }
   ],
   "source": [
    "total_predicts = np.sum(y_test == y_test_pred, axis = 0)\n",
    "print(total_predicts)\n",
    "\n",
    "test_res = total_predicts / y_test.shape[0]\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9e95789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 5 6\n",
      "33 4 6\n",
      "38 2 3\n",
      "77 2 7\n",
      "124 7 4\n",
      "149 2 4\n",
      "151 9 8\n",
      "195 3 5\n",
      "217 6 5\n",
      "233 8 7\n",
      "241 9 8\n",
      "245 3 5\n",
      "247 4 6\n",
      "259 6 0\n",
      "290 8 4\n",
      "300 4 6\n",
      "320 9 7\n",
      "321 2 7\n",
      "340 5 3\n",
      "341 6 4\n",
      "352 5 0\n",
      "358 7 9\n",
      "362 2 7\n",
      "381 3 7\n",
      "406 5 8\n",
      "412 5 3\n",
      "435 8 7\n",
      "444 2 8\n",
      "445 6 0\n",
      "448 9 8\n",
      "464 3 7\n",
      "468 7 9\n",
      "478 5 8\n",
      "479 9 3\n",
      "495 8 0\n",
      "502 5 3\n",
      "507 3 5\n",
      "528 3 2\n",
      "530 9 4\n",
      "531 3 6\n",
      "542 8 2\n",
      "543 8 3\n",
      "551 7 1\n",
      "565 4 9\n",
      "571 4 9\n",
      "578 3 2\n",
      "582 8 2\n",
      "591 8 3\n",
      "619 1 8\n",
      "628 3 9\n",
      "629 2 6\n",
      "659 2 8\n",
      "684 7 2\n",
      "691 8 4\n",
      "707 4 9\n",
      "714 8 5\n",
      "717 0 6\n",
      "720 5 8\n",
      "726 7 5\n",
      "728 2 8\n",
      "738 2 8\n",
      "740 4 9\n",
      "741 2 8\n",
      "760 4 9\n",
      "791 5 9\n",
      "810 7 2\n",
      "839 8 3\n",
      "844 8 7\n",
      "857 5 3\n",
      "924 2 7\n",
      "939 2 0\n",
      "944 3 5\n",
      "947 8 9\n",
      "950 7 2\n",
      "951 5 4\n",
      "956 1 6\n",
      "965 6 0\n",
      "992 9 4\n",
      "999 9 7\n",
      "1003 5 3\n",
      "1012 7 9\n",
      "1014 6 5\n",
      "1039 7 1\n",
      "1044 6 2\n",
      "1050 2 6\n",
      "1062 3 7\n",
      "1068 8 5\n",
      "1101 8 2\n",
      "1107 9 3\n",
      "1112 4 6\n",
      "1114 3 8\n",
      "1119 7 2\n",
      "1124 8 7\n",
      "1128 3 7\n",
      "1181 6 1\n",
      "1192 9 4\n",
      "1194 7 9\n",
      "1198 8 4\n",
      "1200 8 3\n",
      "1202 8 5\n",
      "1204 3 2\n",
      "1208 3 9\n",
      "1224 2 5\n",
      "1226 7 2\n",
      "1232 9 4\n",
      "1234 8 5\n",
      "1242 4 9\n",
      "1247 9 0\n",
      "1248 8 5\n",
      "1256 2 3\n",
      "1260 7 1\n",
      "1283 7 2\n",
      "1289 5 9\n",
      "1299 5 7\n",
      "1319 8 3\n",
      "1325 8 6\n",
      "1326 7 2\n",
      "1328 7 9\n",
      "1337 2 6\n",
      "1364 8 2\n",
      "1378 5 6\n",
      "1391 4 9\n",
      "1393 5 3\n",
      "1402 2 7\n",
      "1433 8 3\n",
      "1440 4 9\n",
      "1444 6 4\n",
      "1453 4 9\n",
      "1467 5 9\n",
      "1500 7 1\n",
      "1514 2 8\n",
      "1520 7 8\n",
      "1522 7 9\n",
      "1525 5 0\n",
      "1527 1 6\n",
      "1530 8 7\n",
      "1549 4 6\n",
      "1553 9 3\n",
      "1559 9 3\n",
      "1569 6 4\n",
      "1581 7 9\n",
      "1609 2 6\n",
      "1621 0 6\n",
      "1634 4 7\n",
      "1640 9 4\n",
      "1671 7 9\n",
      "1678 2 0\n",
      "1681 3 7\n",
      "1709 9 5\n",
      "1717 8 0\n",
      "1718 7 2\n",
      "1722 2 4\n",
      "1740 8 5\n",
      "1751 4 2\n",
      "1754 7 2\n",
      "1759 8 6\n",
      "1765 3 5\n",
      "1772 7 9\n",
      "1782 8 4\n",
      "1790 2 7\n",
      "1813 8 3\n",
      "1828 3 7\n",
      "1850 8 7\n",
      "1855 8 3\n",
      "1878 8 3\n",
      "1901 9 4\n",
      "1903 7 4\n",
      "1917 5 8\n",
      "1930 2 4\n",
      "1938 4 6\n",
      "1952 9 5\n",
      "1970 5 3\n",
      "1973 8 5\n",
      "1981 6 4\n",
      "1982 6 5\n",
      "1984 2 0\n",
      "2004 8 9\n",
      "2016 7 2\n",
      "2024 7 9\n",
      "2033 0 4\n",
      "2035 5 3\n",
      "2037 5 6\n",
      "2040 5 6\n",
      "2043 4 8\n",
      "2044 2 7\n",
      "2053 4 9\n",
      "2063 7 5\n",
      "2068 9 4\n",
      "2070 7 9\n",
      "2098 2 0\n",
      "2099 8 9\n",
      "2109 3 4\n",
      "2110 2 8\n",
      "2118 6 0\n",
      "2129 9 2\n",
      "2130 4 9\n",
      "2135 6 1\n",
      "2138 2 8\n",
      "2182 1 2\n",
      "2185 0 5\n",
      "2186 2 3\n",
      "2189 9 1\n",
      "2266 1 6\n",
      "2272 8 0\n",
      "2293 9 6\n",
      "2298 8 3\n",
      "2299 2 7\n",
      "2325 7 1\n",
      "2326 0 5\n",
      "2369 5 8\n",
      "2371 4 9\n",
      "2378 0 2\n",
      "2380 9 0\n",
      "2387 9 1\n",
      "2393 8 3\n",
      "2395 8 3\n",
      "2406 9 1\n",
      "2408 3 9\n",
      "2422 6 4\n",
      "2425 8 3\n",
      "2473 1 8\n",
      "2488 2 4\n",
      "2534 3 5\n",
      "2545 5 3\n",
      "2548 9 4\n",
      "2556 5 2\n",
      "2560 3 2\n",
      "2574 5 7\n",
      "2598 8 2\n",
      "2607 7 1\n",
      "2610 2 8\n",
      "2617 8 5\n",
      "2635 2 8\n",
      "2648 9 0\n",
      "2654 6 1\n",
      "2658 4 8\n",
      "2670 5 8\n",
      "2695 7 4\n",
      "2713 0 8\n",
      "2720 9 4\n",
      "2770 3 4\n",
      "2771 4 9\n",
      "2780 2 3\n",
      "2810 5 0\n",
      "2832 5 3\n",
      "2850 5 3\n",
      "2863 9 4\n",
      "2866 6 4\n",
      "2896 8 0\n",
      "2906 3 5\n",
      "2921 3 0\n",
      "2925 5 0\n",
      "2927 3 2\n",
      "2939 9 5\n",
      "2945 3 7\n",
      "2953 3 5\n",
      "2990 8 9\n",
      "2995 6 5\n",
      "3005 9 1\n",
      "3060 9 7\n",
      "3073 1 2\n",
      "3102 5 3\n",
      "3117 5 9\n",
      "3130 6 0\n",
      "3145 5 9\n",
      "3189 7 4\n",
      "3206 8 3\n",
      "3225 7 1\n",
      "3240 9 3\n",
      "3269 6 2\n",
      "3329 7 2\n",
      "3330 2 3\n",
      "3333 7 9\n",
      "3369 9 7\n",
      "3381 3 2\n",
      "3384 2 5\n",
      "3410 4 9\n",
      "3422 6 0\n",
      "3436 2 1\n",
      "3448 3 5\n",
      "3450 0 8\n",
      "3460 9 4\n",
      "3503 9 1\n",
      "3520 6 4\n",
      "3549 3 2\n",
      "3550 6 5\n",
      "3558 5 0\n",
      "3559 8 5\n",
      "3565 5 8\n",
      "3567 8 5\n",
      "3573 7 4\n",
      "3574 0 7\n",
      "3575 7 4\n",
      "3597 9 3\n",
      "3598 1 8\n",
      "3604 7 0\n",
      "3629 8 3\n",
      "3645 5 7\n",
      "3662 8 5\n",
      "3681 2 3\n",
      "3716 9 3\n",
      "3718 4 9\n",
      "3725 6 4\n",
      "3727 8 5\n",
      "3730 7 9\n",
      "3732 8 1\n",
      "3751 7 2\n",
      "3757 8 3\n",
      "3758 4 9\n",
      "3767 7 2\n",
      "3776 5 8\n",
      "3780 4 6\n",
      "3796 2 8\n",
      "3801 6 0\n",
      "3806 5 8\n",
      "3808 7 3\n",
      "3811 2 3\n",
      "3817 2 4\n",
      "3821 9 4\n",
      "3833 8 3\n",
      "3836 7 9\n",
      "3838 7 1\n",
      "3848 7 3\n",
      "3853 6 5\n",
      "3855 5 0\n",
      "3862 2 3\n",
      "3869 9 4\n",
      "3876 2 8\n",
      "3893 5 6\n",
      "3902 5 3\n",
      "3906 1 3\n",
      "3926 9 3\n",
      "3941 4 6\n",
      "3943 3 5\n",
      "3946 2 8\n",
      "3951 8 5\n",
      "3962 3 2\n",
      "3970 9 4\n",
      "3976 7 1\n",
      "3984 9 8\n",
      "3985 9 4\n",
      "4000 9 4\n",
      "4017 4 9\n",
      "4063 6 5\n",
      "4065 0 6\n",
      "4072 5 3\n",
      "4075 8 5\n",
      "4078 9 3\n",
      "4093 9 4\n",
      "4131 5 3\n",
      "4140 8 2\n",
      "4152 5 1\n",
      "4159 8 3\n",
      "4163 9 5\n",
      "4176 2 4\n",
      "4177 5 4\n",
      "4199 7 9\n",
      "4201 1 7\n",
      "4205 2 1\n",
      "4211 6 5\n",
      "4212 1 3\n",
      "4224 9 7\n",
      "4238 7 9\n",
      "4248 2 8\n",
      "4289 2 7\n",
      "4294 9 7\n",
      "4297 7 3\n",
      "4300 5 3\n",
      "4306 3 7\n",
      "4315 5 8\n",
      "4330 5 8\n",
      "4355 5 9\n",
      "4356 5 8\n",
      "4359 5 7\n",
      "4369 9 4\n",
      "4374 5 6\n",
      "4380 8 5\n",
      "4425 9 4\n",
      "4427 2 8\n",
      "4433 7 3\n",
      "4435 3 7\n",
      "4449 6 0\n",
      "4451 2 8\n",
      "4454 9 7\n",
      "4477 0 3\n",
      "4497 8 7\n",
      "4498 7 6\n",
      "4500 9 1\n",
      "4521 2 7\n",
      "4523 8 3\n",
      "4534 9 8\n",
      "4536 6 5\n",
      "4540 7 9\n",
      "4571 6 2\n",
      "4575 4 2\n",
      "4578 7 9\n",
      "4601 8 4\n",
      "4615 2 4\n",
      "4639 8 9\n",
      "4640 8 3\n",
      "4673 9 4\n",
      "4731 8 7\n",
      "4751 4 6\n",
      "4761 9 1\n",
      "4785 3 8\n",
      "4807 8 0\n",
      "4808 3 5\n",
      "4814 6 0\n",
      "4823 9 4\n",
      "4829 8 3\n",
      "4837 7 2\n",
      "4860 4 9\n",
      "4874 9 0\n",
      "4876 2 4\n",
      "4879 8 6\n",
      "4880 0 8\n",
      "4886 7 1\n",
      "4890 8 6\n",
      "4910 9 4\n",
      "4915 5 8\n",
      "4939 2 3\n",
      "4941 2 6\n",
      "4950 2 3\n",
      "4952 6 5\n",
      "4956 8 4\n",
      "4966 7 1\n",
      "4990 3 8\n",
      "5015 9 4\n",
      "5046 3 2\n",
      "5065 8 1\n",
      "5067 3 2\n",
      "5140 3 2\n",
      "5143 3 6\n",
      "5165 0 5\n",
      "5210 9 7\n",
      "5217 2 8\n",
      "5278 8 9\n",
      "5331 1 6\n",
      "5457 1 8\n",
      "5562 2 8\n",
      "5600 7 9\n",
      "5617 4 9\n",
      "5620 7 9\n",
      "5642 1 5\n",
      "5678 8 5\n",
      "5691 4 1\n",
      "5695 0 5\n",
      "5734 3 7\n",
      "5749 8 6\n",
      "5835 7 9\n",
      "5842 4 7\n",
      "5870 0 3\n",
      "5887 7 2\n",
      "5888 4 0\n",
      "5891 5 1\n",
      "5912 3 0\n",
      "5913 5 3\n",
      "5922 5 3\n",
      "5935 3 8\n",
      "5936 4 9\n",
      "5937 5 3\n",
      "5945 3 8\n",
      "5949 7 9\n",
      "5955 3 8\n",
      "5957 5 8\n",
      "5973 3 8\n",
      "5985 5 8\n",
      "5992 7 9\n",
      "6023 3 5\n",
      "6035 2 0\n",
      "6042 5 3\n",
      "6043 5 3\n",
      "6045 3 9\n",
      "6059 3 9\n",
      "6065 3 8\n",
      "6071 9 3\n",
      "6081 9 8\n",
      "6091 9 0\n",
      "6093 2 8\n",
      "6109 2 1\n",
      "6111 2 8\n",
      "6157 9 0\n",
      "6166 9 3\n",
      "6168 9 3\n",
      "6172 9 0\n",
      "6173 9 0\n",
      "6347 8 6\n",
      "6385 5 6\n",
      "6391 2 6\n",
      "6400 0 6\n",
      "6421 3 2\n",
      "6425 6 2\n",
      "6426 0 6\n",
      "6480 2 6\n",
      "6494 3 5\n",
      "6495 8 0\n",
      "6505 9 0\n",
      "6555 8 9\n",
      "6560 9 3\n",
      "6568 9 4\n",
      "6571 9 7\n",
      "6597 0 7\n",
      "6598 5 1\n",
      "6603 8 7\n",
      "6625 8 4\n",
      "6632 9 5\n",
      "6641 8 5\n",
      "6651 0 2\n",
      "6706 5 3\n",
      "6721 2 4\n",
      "6740 9 0\n",
      "6744 2 8\n",
      "6746 5 4\n",
      "6775 5 8\n",
      "6785 2 4\n",
      "6847 6 4\n",
      "6906 2 6\n",
      "6926 6 4\n",
      "7035 8 5\n",
      "7043 9 7\n",
      "7061 9 7\n",
      "7121 8 9\n",
      "7130 3 9\n",
      "7198 8 9\n",
      "7220 8 3\n",
      "7233 3 5\n",
      "7241 5 4\n",
      "7249 2 4\n",
      "7432 7 2\n",
      "7434 4 8\n",
      "7451 5 6\n",
      "7459 9 5\n",
      "7498 5 3\n",
      "7545 8 9\n",
      "7637 2 3\n",
      "7797 5 6\n",
      "7800 3 2\n",
      "7821 3 2\n",
      "7839 1 8\n",
      "7842 5 8\n",
      "7849 3 2\n",
      "7850 5 8\n",
      "7858 3 2\n",
      "7859 5 4\n",
      "7870 5 4\n",
      "7886 2 4\n",
      "7888 5 4\n",
      "7899 1 8\n",
      "7900 1 8\n",
      "7905 3 2\n",
      "7917 2 4\n",
      "7918 5 8\n",
      "7921 8 1\n",
      "7928 1 8\n",
      "7945 2 6\n",
      "7990 1 8\n",
      "8020 1 8\n",
      "8081 4 6\n",
      "8091 2 1\n",
      "8094 2 8\n",
      "8095 4 8\n",
      "8183 8 5\n",
      "8246 3 8\n",
      "8272 3 8\n",
      "8277 3 5\n",
      "8279 8 6\n",
      "8293 3 9\n",
      "8308 3 5\n",
      "8332 9 7\n",
      "8339 8 6\n",
      "8362 3 5\n",
      "8406 4 9\n",
      "8408 8 6\n",
      "8426 9 4\n",
      "8453 5 3\n",
      "8476 8 5\n",
      "8493 1 8\n",
      "8520 4 9\n",
      "8522 8 6\n",
      "8553 5 3\n",
      "8863 5 6\n",
      "9007 3 8\n",
      "9009 7 2\n",
      "9010 2 8\n",
      "9015 7 2\n",
      "9016 0 5\n",
      "9019 7 2\n",
      "9024 7 2\n",
      "9031 7 2\n",
      "9036 7 2\n",
      "9071 1 8\n",
      "9182 3 8\n",
      "9316 8 9\n",
      "9317 6 4\n",
      "9446 2 6\n",
      "9465 5 3\n",
      "9534 7 9\n",
      "9544 9 7\n",
      "9587 9 4\n",
      "9595 2 8\n",
      "9624 3 8\n",
      "9634 0 3\n",
      "9642 9 7\n",
      "9643 1 7\n",
      "9679 6 3\n",
      "9692 9 7\n",
      "9698 6 5\n",
      "9700 2 6\n",
      "9716 2 0\n",
      "9729 5 6\n",
      "9732 8 5\n",
      "9733 9 8\n",
      "9738 4 6\n",
      "9740 9 4\n",
      "9741 9 7\n",
      "9744 8 1\n",
      "9745 4 2\n",
      "9749 5 6\n",
      "9751 2 0\n",
      "9752 2 0\n",
      "9768 2 0\n",
      "9770 5 0\n",
      "9777 5 0\n",
      "9779 2 0\n",
      "9780 8 1\n",
      "9808 9 4\n",
      "9811 2 8\n",
      "9839 2 7\n",
      "9847 2 3\n",
      "9855 2 8\n",
      "9856 9 4\n",
      "9858 6 3\n",
      "9867 2 8\n",
      "9879 0 6\n",
      "9883 5 6\n",
      "9892 8 6\n",
      "9893 2 8\n",
      "9904 2 0\n",
      "9905 3 7\n",
      "9925 3 2\n",
      "9941 5 6\n",
      "9944 3 9\n",
      "9970 5 3\n",
      "9980 2 3\n",
      "9982 5 6\n",
      "9986 3 8\n",
      "646\n"
     ]
    }
   ],
   "source": [
    "# 틀린거 찾아보기\n",
    "n = 0\n",
    "for i, y in enumerate(y_test):\n",
    "    if y != y_test_pred[i]:\n",
    "        print(i, y, y_test_pred[i])\n",
    "        n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5f8fb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAEvCAYAAAAtufaDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAARK0lEQVR4nO3db4xd877H8c9Hq5Ii/nVUQ+khQuRykU3EkZNy7jn+PWh5IIeQSk6URKnwwJ+Q05AbjZw6GkpSKlTOIUpdFXLrfxCX2JWiRRF/QlPt0IieB9q0/d4HsySjZrp+M3vP3vOt9yuZzN5rf+e3vmtW59O11/7ttR0RAoCsdut2AwDQCkIMQGqEGIDUCDEAqRFiAFIjxACkNraTK5swYUJMmTKlk6sEsItYsWLFdxHRs+PylkLM9lmS5ksaI+mBiJi7s/opU6ao2Wy2skoAv1G2vxpo+bCfTtoeI2mBpLMlHSPpQtvHDHc8ABiOVs6JnSzps4j4PCK2SHpM0rT2tAUAZVoJsYMlfd3v/jfVMgDomBF/ddL2TNtN283e3t6RXh2A35hWQmytpMn97h9SLfuFiFgYEY2IaPT0/OqFBQBoSSsh9o6kI23/zvY4SX+RtKw9bQFAmWFPsYiIrbZnSVquvikWD0bE6rZ1BgAFWponFhHPSXquTb0AwJDxtiMAqRFiAFIjxACkRogBSI0QA5AaIQYgNUIMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNUIMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNUIMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNUIMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNUIMQGpju90A6v3www+1NaeeemrRWB9//HFR3b777ltUd88999TWXHTRRUVjAcPRUojZ/lLSJknbJG2NiEY7mgKAUu04Ejs9Ir5rwzgAMGScEwOQWqshFpKet73C9syBCmzPtN203ezt7W1xdQDwS62G2GkRcaKksyVdafsPOxZExMKIaEREo6enp8XVAcAvtRRiEbG2+r5B0lOSTm5HUwBQatghZntP23v/fFvSnyWtaldjAFCilVcnJ0p6yvbP4/wrIv63LV0BQKFhh1hEfC7pP9vYyy6j9AWM119/vahuzpw5tTVr1qwpGqv6T6fW9u3bi+o2btxYW7N06dKisZYvX15U9/jjjxfVZVc64XjBggW1Neecc06L3YxeTLEAkBohBiA1QgxAaoQYgNQIMQCpEWIAUiPEAKRGiAFIjRADkJojomMrazQa0Ww2O7a+kXDrrbfW1tx9991FY5XMdu+WMWPGFNWNHz++tmbTpk1FY5X+Wyx918FvRcnv49prry0a64477mi1nRFje8VAV4/mSAxAaoQYgNQIMQCpEWIAUiPEAKRGiAFIjRADkBohBiA1QgxAaszYr5Reo/6EE06ordm8eXOr7exSGo1fTbIe0LHHHltU184Z+9dff31R3T777FNUV/L5CrfddlvRWN34LIFt27Z1fJ2lmLEPYJdEiAFIjRADkBohBiA1QgxAaoQYgNQIMQCpEWIAUhvb7QZQr6enp7Zm6tSpRWPNnDmzqO6II44oqitxwAEHFNXttddebVtnt5Tsq/nz5xeN1Y3JrhlxJAYgNUIMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNWbsV4466qiiunvvvbe25rHHHisa65ZbbimqO+yww2prDjnkkKKxMLK2bNlSWzNv3rwOdPJLU6ZM6fg6O6X2SMz2g7Y32F7Vb9n+tl+w/Wn1fb+RbRMABlbydPIhSWftsOwGSS9FxJGSXqruA0DH1YZYRLwmaeMOi6dJeri6/bCk6e1tCwDKDPfE/sSIWFfd/lbSxDb1AwBD0vKrk9H3wZWDfnil7Zm2m7abJZ/JBwBDMdwQW297kiRV3zcMVhgRCyOiERGNkmstAcBQDDfElkmaUd2eIenp9rQDAENTMsXiUUn/J+ko29/Y/qukuZL+ZPtTSf9V3QeAjqud7BoRFw7y0B/b3AsADJn7zst3RqPRiGaz2bH1AZ321Vdf1dYcfvjhbV3nbrvVnxVatmxZ0Vhnn312q+2MGNsrIqKx43LeOwkgNUIMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNa6xj1Fj8+bNRXUl17Fvt3HjxhXVLV68eIQ7+bXJkyfX1ozmmfit4kgMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNSa7oiUllzd/6623isa69dZbi+qef/75orp2OvPMM4vqli9f3rZ12i6qW7BgQdvWmRFHYgBSI8QApEaIAUiNEAOQGiEGIDVCDEBqhBiA1AgxAKkRYgBSY8Y+BvTTTz8V1c2fP7+25qabbioaq2T2v1Q+k72d2jkTv9Shhx5aVLcrX3q6BEdiAFIjxACkRogBSI0QA5AaIQYgNUIMQGqEGIDUCDEAqRFiAFJjxn4CP/zwQ23N0qVLi8aaOnVqUd2ll15aVPfGG28U1ZWYN29e28Z67733iuoWL17ctnWWKn1nwqJFi0a4k11D7ZGY7Qdtb7C9qt+yObbX2l5ZfZ0zsm0CwMBKnk4+JOmsAZb/IyKOr76ea29bAFCmNsQi4jVJGzvQCwAMWSsn9mfZfr96urnfYEW2Z9pu2m729va2sDoA+LXhhth9ko6QdLykdZIGPSMbEQsjohERjZ6enmGuDgAGNqwQi4j1EbEtIrZLul/Sye1tCwDKDCvEbE/qd/c8SasGqwWAkVQ7T8z2o5KmSppg+xtJf5M01fbxkkLSl5IuH7kWAWBwtSEWERcOsJhZeB20ZMmS2porrriiaKw99tijqG7cuHFFdXPnzq2tmT17dtFYpb2VeOWVV4rqHnnkkbats1Tp5bVfffXVorrTTz+9hW7y421HAFIjxACkRogBSI0QA5AaIQYgNUIMQGqEGIDUCDEAqRFiAFLj8tRdNH369KK65cuXt22d5557blHdLbfcUlR33HHHtdLOsJRc0umyyy7rQCcj6/bbby+qGzu2/s+4dH9mxJEYgNQIMQCpEWIAUiPEAKRGiAFIjRADkBohBiA1QgxAaoQYgNQcER1bWaPRiGaz2bH1dcsDDzxQVHf11VcX1W3evLm25pRTTika6+WXXy6qa+f17kt9++23RXVnnHFGbc2aNWtabWdYGo1GbU27/wbGjx9fW/PFF18UjTVhwoRW2xkxtldExK9+wRyJAUiNEAOQGiEGIDVCDEBqhBiA1AgxAKkRYgBSI8QApEaIAUiNa+wP0Ztvvllbc9VVVxWNtWXLlqK6np6e2pq77767aKzSmfhbt24tqvvkk09qa5599tmisUq3Yd26dUV17fTiiy8W1Z100km1NXfddVfRWKUz+5955pnamiuuuKJorCeeeKKobjThSAxAaoQYgNQIMQCpEWIAUiPEAKRGiAFIjRADkBohBiA1JrsO0VtvvVVbUzqJtdQll1xSW3PiiScWjfX9998X1d17771FdXPmzCmqK1F6qXTbtTUTJ04sGmvJkiVFdSWXnZbKJhPffPPNRWOVTjj+7LPPamsmTZpUNFZGtUditifbfsX2h7ZX255dLd/f9gu2P62+7zfy7QLAL5U8ndwq6bqIOEbSKZKutH2MpBskvRQRR0p6qboPAB1VG2IRsS4i3q1ub5L0kaSDJU2T9HBV9rCk6SPUIwAMakgn9m1PkXSCpLclTYyIn9+J+62kspMQANBGxSFmey9JT0q6JiJ+7P9Y9J2RHfCsrO2Ztpu2m729vS01CwA7Kgox27urL8D+GRFLq8XrbU+qHp8kacNAPxsRCyOiERGNkkvKAMBQlLw6aUmLJH0UEXf2e2iZpBnV7RmSnm5/ewCwcyXzxH4v6RJJH9heWS27SdJcSY/b/qukryRdMCIdAsBO1IZYRLwhabDZhX9sbzsAMDTM2K8sW7asqO7GG29s2zpnzJhRXyRp9uzZtTWrV68uGuvcc88tqvv666+L6tqpdMb+ddddV1tz9dVXF401efLkorpuGDu27M/z6KOPHuFORjfeOwkgNUIMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNWbsV6ZNm1ZUt9tu7cv9kmvFS9JJJ51UW7Nhw4AXERkV9t1336K6iy++uKhu7ty5tTVjxowpGgv5cSQGIDVCDEBqhBiA1AgxAKkRYgBSI8QApEaIAUiNEAOQGpNdu+ihhx7qdguDKp2Ie+CBB9bWvP3220VjjeZLRWP04kgMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNUIMQGrM2K8sWrSoqG7WrFm1Neeff37RWI8++mhRXTsddNBBRXULFiwoqps+fXoL3QCt40gMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNUIMQGqOiI6trNFoRLPZ7Nj6AOw6bK+IiMaOy2uPxGxPtv2K7Q9tr7Y9u1o+x/Za2yurr3NGonEA2JmS905ulXRdRLxre29JK2y/UD32j4j4+8i1BwA7VxtiEbFO0rrq9ibbH0k6eKQbA4ASQzqxb3uKpBMk/fxBgrNsv2/7Qdv7tbs5AKhTHGK295L0pKRrIuJHSfdJOkLS8eo7Ups3yM/NtN203ezt7W29YwDopyjEbO+uvgD7Z0QslaSIWB8R2yJiu6T7JZ080M9GxMKIaEREo6enp119A4CkslcnLWmRpI8i4s5+yyf1KztP0qr2twcAO1fy6uTvJV0i6QPbK6tlN0m60PbxkkLSl5IuH4H+AGCnSl6dfEOSB3joufa3AwBDw9uOAKRGiAFIjRADkBohBiA1QgxAaoQYgNQIMQCpEWIAUiPEAKRGiAFIjRADkBohBiA1QgxAaoQYgNQIMQCpEWIAUiPEAKRGiAFIjRADkJojonMrs3slfbXD4gmSvutYE+2XvX8p/zZk71/Kvw2d6P+wiPjV5z52NMQGYrsZEY2uNtGC7P1L+bche/9S/m3oZv88nQSQGiEGILXREGILu91Ai7L3L+Xfhuz9S/m3oWv9d/2cGAC0YjQciQHAsHUtxGyfZXuN7c9s39CtPlph+0vbH9heabvZ7X5K2H7Q9gbbq/ot29/2C7Y/rb7v180ed2aQ/ufYXlvth5W2z+lmjztje7LtV2x/aHu17dnV8kz7YLBt6Mp+6MrTSdtjJH0i6U+SvpH0jqQLI+LDjjfTAttfSmpERJr5Pbb/IOnfkhZHxH9Uy+6QtDEi5lb/oewXEdd3s8/BDNL/HEn/joi/d7O3ErYnSZoUEe/a3lvSCknTJV2qPPtgsG24QF3YD906EjtZ0mcR8XlEbJH0mKRpXerlNyUiXpO0cYfF0yQ9XN1+WH3/IEelQfpPIyLWRcS71e1Nkj6SdLBy7YPBtqEruhViB0v6ut/9b9TFX0ILQtLztlfYntntZlowMSLWVbe/lTSxm80M0yzb71dPN0ftU7H+bE+RdIKkt5V0H+ywDVIX9gMn9ltzWkScKOlsSVdWT3VSi77zC9lesr5P0hGSjpe0TtK8rnZTwPZekp6UdE1E/Nj/sSz7YIBt6Mp+6FaIrZU0ud/9Q6plqUTE2ur7BklPqe9pckbrq/McP5/v2NDlfoYkItZHxLaI2C7pfo3y/WB7d/X98f8zIpZWi1Ptg4G2oVv7oVsh9o6kI23/zvY4SX+RtKxLvQyL7T2rk5qyvaekP0tatfOfGrWWSZpR3Z4h6eku9jJkP//xV87TKN4Pti1pkaSPIuLOfg+l2QeDbUO39kPXJrtWL7/eJWmMpAcj4r+70sgw2T5cfUdfkjRW0r8ybIPtRyVNVd9VB9ZL+puk/5H0uKRD1XeVkQsiYlSePB+k/6nqewoTkr6UdHm/80ujiu3TJL0u6QNJ26vFN6nvnFKWfTDYNlyoLuwHZuwDSI0T+wBSI8QApEaIAUiNEAOQGiEGIDVCDEBqhBiA1AgxAKn9P6rOYj44nMl9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "image = np.reshape(X_test[9980], [28, 28])\n",
    "plt.imshow(image, cmap = 'Greys')\n",
    "plt.show()\n",
    "\n",
    "## 학습(이전 학습 내용을 반영하기때문에)을 잘못하면 너무 명백한 예측도 잘 하지못하게된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d4b8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN (Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd99a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,111,946\n",
      "Trainable params: 1,111,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5,5), padding = 'valid', activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(layers.MaxPool2D(2, 2))       # 사진 줄이기\n",
    "model.add(layers.Conv2D(64, (5,5), padding = 'valid', activation = 'relu'))\n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "model.add(layers.Flatten())             #### 2번 ~ 3번이면 충분함\n",
    "model.add(layers.Dense(1024, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.5))                    ### overfit 방지, 일반화된 이미지를 도출\n",
    "model.add(layers.Dense(10, activation = 'relu'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ada0a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45927ef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:230 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-794d2e851de8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(X_train_centered, y_train_onehot, batch_size = 64, epochs = 20, \n\u001b[0m\u001b[0;32m      2\u001b[0m                    validation_data = (X_valid_centered, y_valid_onehot))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\CPB06GameN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:230 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_centered, y_train_onehot, batch_size = 64, epochs = 20, \n",
    "                   validation_data = (X_valid_centered, y_valid_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f40a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 21), history.history['loss'], label = 'loss')\n",
    "plt.plot(np.arange(1, 21), history.history['val_loss'], label = 'val_loss')\n",
    "plt.legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b07c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(mode.predict(X_test_centered[:10]), axis = 1)\n",
    "# [ 7 2 1 0 4 1 4 9 5 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab922c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[:10])\n",
    "\n",
    "# [7 1 0 4 1 4 9 5 9]\n",
    "## 10개 모두 정답\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aef461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ec473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a8348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
